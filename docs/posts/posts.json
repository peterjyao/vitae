[
  {
    "path": "posts/2021-08-04-simulating-data/",
    "title": "simulating data",
    "description": "Attempts to simulate data for a later post.",
    "author": [
      {
        "name": "Peter Yao",
        "url": {}
      }
    ],
    "date": "2021-08-04",
    "categories": [
      "work-in-progress"
    ],
    "contents": "\nI want to describe an old project that required some interesting data analysis but first I need to find a way to create some artificial data. I basically need data from a step function, with some noise added. Each step has to have some “measurement” points in the middle. At first I tried to make my own step function in a naïve way, as shown below. I did not realise literally until I started writing this post and wrote a function called step_func that R has a built-in function stats::stepfun, which I need to learn more about.\n\n\n\n\n\nstep_func <- function(n = 100L, m = 10L) {\n  dat <- sapply(1:n, function(x) rep(x, m))\n  \n  data.frame(\n    x = 0:((n * m )- 1), \n    y = as.vector(dat)\n  )\n}\n\nstep_dat <- step_func(n = 20, m = 4)\nggplot2::ggplot(step_dat, ggplot2::aes(x = x, y = y)) +\n  ggplot2::geom_point()\n\n\n\n\nThis is fine but I also need occasionally lower steps. It turned out one way to do this is to essentially simulate the underlying process that I was studying, by using a cumulative sum, with the step height sometimes decreased according to a probability in rbinom. I also added noise in the function below, and drop some of the “measurement” points randomly.\n\n\nset.seed(100)\n\nmake_data <- function(n = 100L,\n                      m = 10L,\n                      p = 0.15,\n                      rmin = 0.2,\n                      rmax = 0.8,\n                      sd_x = 0.02,\n                      sd_y = 0.02,\n                      del_frac = 0.05) {\n\n  sim <- data.frame(\n    x = seq(m, n * m, by = m),\n    y = 1 - rbinom(n, 1, p) * runif(n, min = rmin, max = rmax)\n    )\n  \n  meas <- data.frame(\n    x = 0:(n * m),\n    noise_x = rnorm((n * m) + 1, mean = 0, sd = sd_x),\n    noise_y = rnorm((n * m) + 1, mean = 0, sd = sd_y)\n  )\n  \n  sim_noisy <- merge(sim, meas, all = TRUE)\n  sim_noisy$y_noisy <- rowSums(sim_noisy[, c(\"y\", \"noise_y\")], na.rm = TRUE)\n  sim_noisy$x_noisy <- rowSums(sim_noisy[, c(\"x\", \"noise_x\")], na.rm = TRUE)\n  sim_noisy$cumul_noisy <- cumsum(sim_noisy$y_noisy)\n\n  del_nrows = as.integer(n * m * del_frac)\n  del_rows <- sample(n * m, del_nrows, replace = FALSE)\n  \n  sim_noisy[-del_rows, c(\"x_noisy\", \"cumul_noisy\")]\n}\n\nsim_dat <- make_data(n = 20, m = 4)\n\nggplot2::ggplot(sim_dat, ggplot2::aes(x = x_noisy, y = cumul_noisy)) +\n  ggplot2::geom_point()\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-08-04-simulating-data/simulating-data_files/figure-html5/step-1.png",
    "last_modified": "2021-08-04T22:50:33+02:00",
    "input_file": "simulating-data.knit.md"
  },
  {
    "path": "posts/2021-07-31-autoportrait/",
    "title": "autoportrait",
    "description": "Documenting how this blog was set up",
    "author": [
      {
        "name": "Peter Yao",
        "url": {}
      }
    ],
    "date": "2021-07-31",
    "categories": [
      "distill"
    ],
    "contents": "\nThis blog was set up following the instructions from Alison Hill. To make the rest of the site match the About Me page better (created with the postcards package), I added a bit to the site styles.css, which I expect I will play with more in the future.\n\n@import url(\"https://fonts.googleapis.com/css2?family=Roboto+Slab&display=swap\");\n\nh1, h2, h3, h4, h5, h6 {\n  font-family: \"Roboto Slab\";\n}\n\nbody {\n  font-family: \"Roboto Slab\";\n  background-color: #f5e9dd;\n}\n\n@import url(\"https://fonts.googleapis.com/css2?family=Roboto+Slab&display=swap\");\n\nh1, h2, h3, h4, h5, h6 {\n  font-family: \"Roboto Slab\";\n}\n\nbody {\n  font-family: \"Roboto Slab\";\n  background-color: #f5e9dd;\n}\n\nAt the moment there is a slight difference in how the navbar looks on the pages. Hopefully I can figure out how to fix that at some point.\nI wanted to try to use the same data source I used for my CV, which I partially made using the vitae package–I say partially, because I ended up fine tuning it directly in the LaTeX file. It’s a bit hacky but works. Below is for the “Experience” section.\n\n\nlibrary(\"glue\")\n\ndata_source_root <- \"https://raw.githubusercontent.com/peterjyao/cv/main/data\"\n\nexperience <- read.csv(url(glue(\"{data_source_root}/experience.csv\")))\n\n# fix the date formatting\nexperience$dates <- gsub(\"\\'\", \"20\", experience$dates)\nexperience$dates <- gsub(\"-\", \" - \", experience$dates)\n\nexperience$description_formatted <- glue(\n    .envir = experience,\n    \"**{role}**&nbsp;&nbsp;|&nbsp;&nbsp;{dates}\",\n    \"*{org}*&nbsp;&nbsp;|&nbsp;&nbsp;{place}\",\n    \"{description}\",\n    .sep = \"<br>\"\n  )\n\ncat(paste(experience$description_formatted, collapse = \"<br><br>\"))\n\n\n\nI used similar code for the “Education” and “Languages” section, so I should probably make a function out of it.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-01T00:00:25+02:00",
    "input_file": {}
  }
]
